{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bd159b69",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lee un ejercicio desde una imagen\n",
        "# y lo convierte en un documento LaTeX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "glBtW4t4ewkI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "glBtW4t4ewkI",
        "outputId": "0d30bea3-2e64-4217-a74e-65538bee6244"
      },
      "outputs": [],
      "source": [
        "%%capture outputtext\n",
        "\n",
        "# Colab:\n",
        "!pip install langchain-community\n",
        "!pip install langchain-ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!ollama serve &>/dev/null&\n",
        "\n",
        "# # Local:\n",
        "# import os\n",
        "# environment= 'local'\n",
        "# os.system('ollama serve &>/dev/null&')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c91ea94",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !ollama pull llama3.1\n",
        "!ollama pull llama3.2-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "-voJEtbKioep",
      "metadata": {
        "id": "-voJEtbKioep"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from IPython.display import display, Markdown, Latex\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "import base64\n",
        "import httpx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wliZJbFckIB5",
      "metadata": {
        "id": "wliZJbFckIB5"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate(\n",
        "    [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Transcribe el ejercicio mostrado en la imagen en un documento LaTeX.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source_type\": \"base64\",\n",
        "                    \"mime_type\": \"{image_mime_type}\",\n",
        "                    \"data\": \"{image_data}\",\n",
        "                    \"cache_control\": {\"type\": \"{cache_type}\"},\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "70d379b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "myllm = ChatOllama(\n",
        "    model = \"llama3.2-vision\",\n",
        "    # model = \"llama3.1\",\n",
        "    # model = \"llama3.1:8b\",\n",
        "    temperature = 0.8,  # default\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a1a6c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No remote file name, uses \"curl_response\"\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0curl: (6) Could not resolve host: url\n"
          ]
        }
      ],
      "source": [
        "filename = 'ejercicio-calorimetria.png'\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/frautn/llamita/main/data/' + filename\n",
        "!curl -OL {url}\n",
        "\n",
        "with open(filename, \"rb\") as image_file:\n",
        "    image_data = base64.b64encode(image_file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "424defe8-d85c-4e45-a88d-bf6f910d5ebb",
      "metadata": {
        "id": "424defe8-d85c-4e45-a88d-bf6f910d5ebb"
      },
      "outputs": [],
      "source": [
        "# En Colab usando T4 tarda 1 minuto.\n",
        "chain = prompt | myllm\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"image_data\": image_data.decode('utf8'),\n",
        "        \"image_mime_type\": \"image/png\",\n",
        "        \"cache_type\": \"ephemeral\",\n",
        "    }\n",
        ")\n",
        "print(response.text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cdbefe4",
      "metadata": {},
      "outputs": [],
      "source": [
        "response.usage_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a9edb3",
      "metadata": {},
      "source": [
        "{'input_tokens': 20, 'output_tokens': 454, 'total_tokens': 474}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llamita",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
