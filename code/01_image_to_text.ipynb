{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bd159b69",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lee un ejercicio desde una imagen\n",
        "# y lo convierte en un documento LaTeX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "glBtW4t4ewkI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "glBtW4t4ewkI",
        "outputId": "0d30bea3-2e64-4217-a74e-65538bee6244"
      },
      "outputs": [],
      "source": [
        "%%capture outputtext\n",
        "\n",
        "# Colab:\n",
        "!pip install langchain-community\n",
        "!pip install langchain-ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!ollama serve &>/dev/null&\n",
        "\n",
        "# # Local:\n",
        "# import os\n",
        "# environment= 'local'\n",
        "# os.system('ollama serve &>/dev/null&')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c91ea94",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !ollama pull llama3.1\n",
        "# !ollama pull llama3.2-vision\n",
        "!ollama pull qwen2.5vl:7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "-voJEtbKioep",
      "metadata": {
        "id": "-voJEtbKioep"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from IPython.display import display, Markdown, Latex\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "import base64\n",
        "import httpx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d379b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "myllm = ChatOllama(\n",
        "    model = \"qwen2.5vl:7b\",\n",
        "    # model = \"llama3.2-vision\",\n",
        "    # model = \"llama3.1\",\n",
        "    # model = \"llama3.1:8b\",\n",
        "    # temperature = 0.8,  # default en llama\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a1a6c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No remote file name, uses \"curl_response\"\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0curl: (6) Could not resolve host: url\n"
          ]
        }
      ],
      "source": [
        "filename = 'jackson_2_7.jpg'\n",
        "# filename = 'ejercicio-calorimetria.png'\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/frautn/llamita/dev/data/' + filename\n",
        "# url = 'https://raw.githubusercontent.com/frautn/llamita/main/data/' + filename\n",
        "!curl -OL {url}\n",
        "\n",
        "with open(filename, \"rb\") as image_file:\n",
        "    image_data = base64.b64encode(image_file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ae05f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "message = {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"Transcribe the text in the image. Don't solve the problem.\",\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"image\",\n",
        "            \"source_type\": \"base64\",\n",
        "            \"data\": image_data.decode('utf8'),\n",
        "            \"mime_type\": \"image/jpg\",\n",
        "        },\n",
        "    ],\n",
        "}\n",
        "\n",
        "response = myllm.invoke([message])\n",
        "print(response.text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b6f038e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejercicio resuelto a mano.\n",
        "\n",
        "filename = 'parcial1_2025_1a_00.jpg'\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/frautn/llamita/dev/data/' + filename\n",
        "# url = 'https://raw.githubusercontent.com/frautn/llamita/main/data/' + filename\n",
        "!curl -OL {url}\n",
        "\n",
        "with open(filename, \"rb\") as image_file:\n",
        "    image_data = base64.b64encode(image_file.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33594634",
      "metadata": {},
      "outputs": [],
      "source": [
        "message = {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"Transcribe the text in the image into a LaTeX document.\",\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"image\",\n",
        "            \"source_type\": \"base64\",\n",
        "            \"data\": image_data.decode('utf8'),\n",
        "            \"mime_type\": \"image/jpg\",\n",
        "        },\n",
        "    ],\n",
        "}\n",
        "\n",
        "response = myllm.invoke([message])\n",
        "print(response.text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ddaa68",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejercicio resuelto a mano. dos Ã­tems.\n",
        "\n",
        "filename = 'parcial1_2025_1_00.jpg'\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/frautn/llamita/dev/data/' + filename\n",
        "# url = 'https://raw.githubusercontent.com/frautn/llamita/main/data/' + filename\n",
        "!curl -OL {url}\n",
        "\n",
        "with open(filename, \"rb\") as image_file:\n",
        "    image_data = base64.b64encode(image_file.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4061f6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "message = {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"Transcribe the text in the image into a LaTeX document.\",\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"image\",\n",
        "            \"source_type\": \"base64\",\n",
        "            \"data\": image_data.decode('utf8'),\n",
        "            \"mime_type\": \"image/jpg\",\n",
        "        },\n",
        "    ],\n",
        "}\n",
        "\n",
        "response = myllm.invoke([message])\n",
        "print(response.text())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llamita",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
