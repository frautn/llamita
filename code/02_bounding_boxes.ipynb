{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bd159b69",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lee un ejercicio desde una imagen\n",
        "# y lo convierte en un documento LaTeX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "glBtW4t4ewkI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "glBtW4t4ewkI",
        "outputId": "0d30bea3-2e64-4217-a74e-65538bee6244"
      },
      "outputs": [],
      "source": [
        "%%capture outputtext\n",
        "\n",
        "# Colab:\n",
        "!pip install langchain-community\n",
        "!pip install langchain-ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!ollama serve &>/dev/null&\n",
        "\n",
        "# # Local:\n",
        "# import os\n",
        "# environment= 'local'\n",
        "# os.system('ollama serve &>/dev/null&')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c91ea94",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !ollama pull llama3.1\n",
        "# !ollama pull llama3.2-vision\n",
        "!ollama pull qwen2.5vl:7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de4655f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture outputtext\n",
        "\n",
        "# Si se desea generar pdfs\n",
        "! apt-get install -y texlive-xetex texlive-fonts-recommended texlive-latex-extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-voJEtbKioep",
      "metadata": {
        "id": "-voJEtbKioep"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from IPython.display import display, Markdown, Latex\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "import base64\n",
        "import httpx\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d379b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "myllm = ChatOllama(\n",
        "    model = \"qwen2.5vl:7b\",\n",
        "    # model = \"llama3.2-vision\",\n",
        "    # model = \"llama3.1\",\n",
        "    # model = \"llama3.1:8b\",\n",
        "    # temperature = 0.8,  # default en llama\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a1a6c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No remote file name, uses \"curl_response\"\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0curl: (6) Could not resolve host: url\n"
          ]
        }
      ],
      "source": [
        "filename = 'jackson_2_7.jpg'\n",
        "# filename = 'ejercicio-calorimetria.png'\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/frautn/llamita/main/data/' + filename\n",
        "# url = 'https://raw.githubusercontent.com/frautn/llamita/dev/data/' + filename\n",
        "!curl -OL {url}\n",
        "\n",
        "with open(filename, \"rb\") as image_file:\n",
        "    image_data = base64.b64encode(image_file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ae05f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "message = {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"Transcribe the text in the image. Don't solve the problem.\",\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"image\",\n",
        "            \"source_type\": \"base64\",\n",
        "            \"data\": image_data.decode('utf8'),\n",
        "            \"mime_type\": \"image/jpg\",\n",
        "        },\n",
        "    ],\n",
        "}\n",
        "\n",
        "response = myllm.invoke([message])\n",
        "print(response.text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d198e38",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "## Load the image\n",
        "\n",
        "# Revisar si se puede usar esto para decode o directamente en qwen sin decode.\n",
        "image = Image.open(filename)\n",
        "\n",
        "## Display the image\n",
        "plt.imshow(image)\n",
        "\n",
        "# ## Get the current axis\n",
        "ax = plt.gca()\n",
        "\n",
        "\n",
        "# [20, 100, 1186, 158]\n",
        "# ## Create a rectangle patch\n",
        "rectangle = Rectangle((20, 100), 1166, 58, linewidth=1, edgecolor='r', facecolor='none')\n",
        "\n",
        "# ## Add the rectangle to the current axis\n",
        "ax.add_patch(rectangle)\n",
        "\n",
        "[20, 200, 1186, 228]\n",
        "rectangle = Rectangle((20, 200), 1166, 28, linewidth=1, edgecolor='r', facecolor='none')\n",
        "ax.add_patch(rectangle)\n",
        "\n",
        "# ## Show the result\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3e10ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%capture outputtext\n",
        "\n",
        "# output = response.text()\n",
        "# output = output.strip(\"```latex\")\n",
        "# file_path_output = \"output_qwen_parcial1_2025_1_00.tex\"\n",
        "\n",
        "# with open(file_path_output, 'w') as file:\n",
        "#     file.write(output)\n",
        "\n",
        "# ! pdflatex {file_path_output}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llamita",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
